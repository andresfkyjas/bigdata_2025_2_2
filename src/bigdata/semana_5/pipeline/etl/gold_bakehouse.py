# Databricks notebook source
# MAGIC %md
# MAGIC ### Example Exploratory Notebook
# MAGIC
# MAGIC Use this notebook to explore the data generated by the pipeline in your preferred programming language.
# MAGIC
# MAGIC **Note**: This notebook is not executed as part of the pipeline.

# COMMAND ----------

# =========================
# SILVER
# =========================
import dlt
from pyspark.sql import functions as F
@dlt.table(
    name="silver_customers",
    comment="Clientes limpios y normalizados"
)
@dlt.expect_or_drop("customer_id_not_null", "customerID IS NOT NULL")
@dlt.expect_or_drop("email_not_null", "email_address IS NOT NULL")
def silver_customers():
    df = dlt.read("bronze_customers")
    return (
        df
        .withColumn("customer_id", F.col("customerID").cast("long"))
        .withColumn("first_name", F.initcap(F.col("first_name")))
        .withColumn("last_name", F.initcap(F.col("last_name")))
        .withColumn("full_name", F.concat_ws(" ", "first_name", "last_name"))
        .withColumn("email", F.lower(F.col("email_address")))
        .withColumn("phone", F.regexp_replace("phone_number", r"\s+", ""))
    )


@dlt.table(
    name="silver_franchises",
    comment="Franquicias limpias y con tipos correctos"
)
@dlt.expect_or_drop("franchise_id_not_null", "franchiseID IS NOT NULL")
def silver_franchises():
    df = dlt.read("bronze_franchises")
    return (
        df
        .withColumn("franchise_id", F.col("franchiseID").cast("long"))
        .withColumn("franchise_name", F.col("name"))
        .withColumn("zipcode_str", F.col("zipcode").cast("string"))
        .withColumn("longitude", F.col("longitude").cast("double"))
        .withColumn("latitude", F.col("latitude").cast("double"))
    )


@dlt.table(
    name="silver_suppliers",
    comment="Proveedores limpios y validados"
)
@dlt.expect_or_drop("supplier_id_not_null", "supplierID IS NOT NULL")
def silver_suppliers():
    df = dlt.read("bronze_suppliers")
    return (
        df
        .withColumn("supplier_id", F.col("supplierID").cast("long"))
        .withColumn("supplier_name", F.col("name"))
        .withColumn(
            "approved_flag",
            F.when(F.upper(F.col("approved")) == "Y", F.lit(True))
             .otherwise(F.lit(False))
        )
    )


@dlt.table(
    name="silver_sales_transactions",
    comment="Transacciones con reglas de calidad y datos derivados"
)
@dlt.expect_or_drop("quantity_positive", "quantity > 0")
@dlt.expect_or_drop("unit_price_non_negative", "unitPrice >= 0")
@dlt.expect("total_price_consistent", "totalPrice = quantity * unitPrice")
def silver_sales_transactions():
    df = dlt.read("bronze_sales_transactions")

    return (
        df
        .withColumn("transaction_id", F.col("transactionID").cast("long"))
        .withColumn("customer_id", F.col("customerID").cast("long"))
        .withColumn("franchise_id", F.col("franchiseID").cast("long"))
        .withColumn("date", F.to_date("dateTime"))
        .withColumn("time", F.date_format("dateTime", "HH:mm:ss"))
        # Enmascarar número de tarjeta (ej: último 4 dígitos)
        .withColumn(
            "card_hash",
            F.sha2(F.col("cardNumber").cast("string"), 256)
        )
    )


@dlt.table(
    name="silver_reviews_chunked",
    comment="Reviews limpias por chunk"
)
@dlt.expect_or_drop("franchise_id_not_null", "franchiseID IS NOT NULL")
def silver_reviews_chunked():
    df = dlt.read("bronze_reviews_chunked")
    return (
        df
        .withColumn("franchise_id", F.col("franchiseID").cast("long"))
        .withColumn("review_date_date", F.to_date("review_date"))
        .withColumn(
            "chunked_text",
            F.trim(F.regexp_replace("chunked_text", r"\s+", " "))
        )
        .filter(F.col("chunked_text").isNotNull() & (F.col("chunked_text") != ""))
    )
