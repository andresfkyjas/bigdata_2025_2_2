# Databricks notebook source
# MAGIC %md
# MAGIC ### Example Exploratory Notebook
# MAGIC
# MAGIC Use this notebook to explore the data generated by the pipeline in your preferred programming language.
# MAGIC
# MAGIC **Note**: This notebook is not executed as part of the pipeline.

# COMMAND ----------

import dlt
from pyspark.sql import functions as F
@dlt.table(
    name="fact_franchise_reviews_chunked",
    comment="Hecho de reviews por chunk de texto"
)
def fact_franchise_reviews_chunked():
    df = dlt.read("silver_reviews_chunked")
    return df.select(
        "franchise_id",
        "review_date",
        "review_date_date",
        "chunk_id",
        "review_uri",
        "chunked_text"
    )


@dlt.table(
    name="agg_franchise_reviews_daily",
    comment="Agregaci√≥n diaria de reviews por franquicia"
)
def agg_franchise_reviews_daily():
    df = dlt.read("fact_franchise_reviews_chunked")
    return (
        df.groupBy("franchise_id", "review_date_date")
          .agg(
              F.countDistinct("review_uri").alias("num_reviews"),
              F.count("chunk_id").alias("num_chunks"),
              F.avg(F.length("chunked_text")).alias("avg_chunk_length")
          )
    )

